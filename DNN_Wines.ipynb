{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN_Wines.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLm/jrsx2r321ECbDWbF7h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjiGT/Hitmonchan/blob/master/DNN_Wines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XtZI-ymqQxx",
        "colab_type": "text"
      },
      "source": [
        "<font color='red'>***video link***</font> --> https://youtu.be/0lqjMFEtK78\n",
        "\n",
        "#<font color='redr'> ***Buliding a Deep Neural Network on Wines Quality Dataset (Kaggle)</font>***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UefEzTJ_mAWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjAlj0PSmSuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"datasets_35901_52633_winequalityN.csv\").dropna()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQXFOpwSmlZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0byIxB12m4t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"type\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYZ9azgpm9fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red=df.loc[df[\"type\"].isin([\"red\"])]\n",
        "red"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcv1JNRPnDuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "white=df.loc[df[\"type\"].isin([\"white\"])]\n",
        "white"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNCrn9kEnHW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.isnull(df).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSSSLs6enPDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"target\"] = np.where(df[\"type\"]=='red',1,0)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_khZNy66nXv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(df, diag_kind='kde',hue='type',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYdghTUwxcBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz-rm2xfnxXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = df.iloc[:,1:13]\n",
        "\n",
        "y = np.ravel(df.target) #return contiguous flattened array\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42) #random split into train and test set\n",
        "print(\"Train_X: \",x_train.size)\n",
        "print(\"Test_Y: \",y_test.size)\n",
        "print(\"Test_X: \", x_test.size)\n",
        "print(\"Train_Y: \", y_train.size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgZqP7acn4sE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "004Ok_Qwn9aX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler().fit(x_train) #std dev ; z-score; do not apply std scaling on output var\n",
        "x_train=scaler.transform(x_train)\n",
        "#print(\"Transformed X Train\",x_train)\n",
        "x_test=scaler.transform(x_test)\n",
        "#print(\"Transformed X Test\",x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkzNf5buoRXh",
        "colab_type": "text"
      },
      "source": [
        "#<font color='red'> ***Neural Net-Building block***\n",
        "\n",
        "\n",
        "> ***Blue print of the model***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuQZrLgooQYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential #2 ways Sequential=simpler, Functional=flexible; versatile\n",
        "from tensorflow.keras.layers import Dense \n",
        "from keras.layers.advanced_activations import ReLU\n",
        "\n",
        "#instatiation \n",
        "model=Sequential() # empty model ; Xavier methodology of intialization of weights\n",
        "\n",
        "model.add(Dense(30, activation='relu', input_shape=(12,))) #1st hidden layer; 30 = no.of units/neurons ; no guideline for how many neurons to start with all HPT\n",
        "\n",
        "#Newly added hidden layer\n",
        "#model.add(Dense(20, activation='relu')) #add one at a time \n",
        "\n",
        "#output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uTERyjkonpu",
        "colab_type": "text"
      },
      "source": [
        "<font color = 'yellow'>***Model as a entire entity ready to build as a basis for performance evaluation***</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDn7DTGFonL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) #values are hpt; exe object loss : error function; optimizer: ADAM HPTs; binary cross entropy is same as log-loss entropy\n",
        "epochs=40 # 1 epoch = times you read dataset(train) not iterations; needs to do early stopping (mandat) also, many epochs leads to overfitting\n",
        "\n",
        "#batch_size=50000\n",
        "batch_size=50017\n",
        "#batch_size=256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noXuHfB0oxf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary() #names given internally by the complier; depends upon how many times you have run the code cell."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shFLWktgo4PZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.3, verbose=True) #outlier analysis must be performed before execution of this line; perform clustering if by univariate analysis it's is not visible/detectable\n",
        "\n",
        "loss,accuracy = model.evaluate(x_test, y_test, verbose=False) #invisible outliers=leverage points when you perform univariate analysis\n",
        "\n",
        "#train and validation set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_U7yN3XpCjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history['accuracy'])\n",
        "print(history.history['val_accuracy']) #history captues accuracy scores on train , test and loss\n",
        "\n",
        "ta = pd.DataFrame(history.history['accuracy']) #training acc\n",
        "va = pd.DataFrame(history.history['val_accuracy']) #validation acc\n",
        "\n",
        "tva = pd.concat([ta,va], axis=1)\n",
        "tva.boxplot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fevgBTRMpVF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.round(model.predict(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1u0dTv1pWfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred[:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUg-oR-2pcpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc = model.evaluate(x_train,y_train,verbose=0)\n",
        "print('Train accuracy: %.3f' %acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RexPjsBkpZ6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc = model.evaluate(x_test,y_test,verbose=0) #verbose for showing the log\n",
        "print('Test accuracy: %.3f' %acc) # %.3f for precision of the values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V2lG6S2piC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "print(pd.DataFrame(metrics.confusion_matrix(y_test, y_pred,labels=[0,1]), index=['true:White','true:Red'], columns=['pred:White', 'pred:Red']))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}